{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "0            Acer_Opalus  0.007812  0.023438  0.023438  0.003906  0.011719   \n",
       "1  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625  0.025391   \n",
       "2   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812  0.003906   \n",
       "3        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859  0.021484   \n",
       "4     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766  0.013672   \n",
       "\n",
       "    margin6   margin7  margin8   margin9  ...  texture55  texture56  \\\n",
       "0  0.009766  0.027344      0.0  0.001953  ...   0.007812   0.000000   \n",
       "1  0.001953  0.019531      0.0  0.000000  ...   0.000977   0.000000   \n",
       "2  0.005859  0.068359      0.0  0.000000  ...   0.154300   0.000000   \n",
       "3  0.019531  0.023438      0.0  0.013672  ...   0.000000   0.000977   \n",
       "4  0.015625  0.005859      0.0  0.000000  ...   0.096680   0.000000   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
       "1   0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
       "2   0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
       "3   0.000000   0.000000   0.020508        0.0        0.0   0.017578   \n",
       "4   0.021484   0.000000   0.000000        0.0        0.0   0.000000   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.000000   0.025391  \n",
       "1   0.039062   0.022461  \n",
       "2   0.020508   0.002930  \n",
       "3   0.000000   0.047852  \n",
       "4   0.000000   0.031250  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ACTIVITE MODELES LINEAIRES & FEUILLES D'ARBRES : KNN et SVM\n",
    "# On importe les librairies dont on aura besoin pour ce tp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "# On charge le dataset\n",
    "house_data = pd.read_csv('Dataset_feuilles_1_train.csv')\n",
    "\n",
    "#nous aurons besoins de ces 2 librairies pour transformer les données, et générer ytest\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#On clean le data set.\n",
    "leaf_data_train = house_data.dropna()\n",
    "leaf_data_train = leaf_data_train.drop(['id'], axis=1) #.values\n",
    "#Conversion en dataframe\n",
    "leaf_data_train = pd.DataFrame(leaf_data_train)\n",
    "leaf_data_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On décompose le dataset et on le transforme en matrices pour pouvoir effectuer notre calcul\n",
    "X = leaf_data_train.iloc[:, 1:] # toutes les colonnes sauf les 2 premieres (indice et species)\n",
    "Y = leaf_data_train['species'] #colonne species en tant que y\n",
    "\n",
    "#nous aurons besoins de ces 2 librairies pour centrer réduire les données\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#l'idée est de faire l'opération sur sur les lignes... et non les labels.\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_Scal = scaler.transform(X)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vu que le jeu de test ne contient pas de labels, nous allons nous contenter du jeu d'entrainement...\n",
      "... et le diviser en jeu d'entrainement et de test (70% train)\n"
     ]
    }
   ],
   "source": [
    "#Vu que le jeu de test ne contient pas de labels, nous allons nous contenter du jeu d'entrainement...\n",
    "#... et le diviser en jeu d'entrainement et de test (70% train)\n",
    "print(\"Vu que le jeu de test ne contient pas de labels, nous allons nous contenter du jeu d'entrainement...\")\n",
    "print(\"... et le diviser en jeu d'entrainement et de test (70% train)\")\n",
    "\n",
    "#On partage les données : 30% en test\n",
    "from sklearn import model_selection\n",
    "xtrain, xtest, ytrain, ytest =  model_selection.train_test_split(X_Scal, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le meilleur nombre de voisins selon GridSearchCV est : {'n_neighbors': 3}\n",
      "la meilleure accuracy selon GridSearchCV est 0.9552\n",
      "le nombre de voisins optimal est de 3\n"
     ]
    }
   ],
   "source": [
    "#Scénario de base : un classifieur KNN, avec gridsearchCV pour optimiser le nbr de voisins\n",
    "#d'abord un GridSearchCV pour obtenir le nbr de voisins optimal\n",
    "\n",
    "#La bibliothèque dont on a besoin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9, 11, 13, 15, 17, 19, 21]} #, 23, 25, 27, 29, 31, 33, 35, 36, 37, 39, 41]}\n",
    "\n",
    "# Le score à optimiser, ici l'accuracy\n",
    "score = 'accuracy'\n",
    "\n",
    "# Préparer la validation croisée\n",
    "knn_grid = KNeighborsClassifier()\n",
    "knn_gridCV = GridSearchCV(knn_grid, param_grid, cv=5)\n",
    "\n",
    "# On fitte le grid KNN\n",
    "knn_gridCV.fit(xtrain, ytrain)\n",
    "\n",
    "#pour obtenir le meilleur voisin\n",
    "print (\"le meilleur nombre de voisins selon GridSearchCV est :\", knn_gridCV.best_params_)\n",
    "print (\"la meilleure accuracy selon GridSearchCV est %.4f\"% knn_gridCV.best_score_)\n",
    "GridCV_best_voisins = knn_gridCV.best_params_\n",
    "GridCV_best_score = knn_gridCV.best_score_\n",
    "\n",
    "mon_index_maison = knn_gridCV.best_params_.get(\"n_neighbors\")\n",
    "print (\"le nombre de voisins optimal est de\", mon_index_maison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On fait donc la prédiction avec {'n_neighbors': 3}  voisins\n",
      "j'obtiens une accuracy de 0.9529 avec 3 voisins.\n"
     ]
    }
   ],
   "source": [
    "#On fait donc la prédiction avec le nombre de voisins optimal fourni par gridsearchCV\n",
    "print(\"On fait donc la prédiction avec\", GridCV_best_voisins,\" voisins\")\n",
    "\n",
    "# un KNN avec le nombre de voisins donné par GridSearchCV\n",
    "knn_gridCV_valide = KNeighborsClassifier(n_neighbors= mon_index_maison)\n",
    "# On créé le modèle avec les données d'entrainement\n",
    "knn_gridCV_valide.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "# Et on prédit\n",
    "y_pred_knn = knn_gridCV_valide.predict(xtest)\n",
    "\n",
    "knn_pred_accuracy = accuracy_score(ytest, y_pred_knn)\n",
    "print(\"j'obtiens une accuracy de %.4f\"% knn_pred_accuracy, \"avec\", mon_index_maison, \"voisins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "#Scénatio alternatif 1 : classifieur SVM sur toutes les données.\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "  \n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['linear', 'sigmoid', 'rbf'], \n",
    "             }   \n",
    "\n",
    "\n",
    "svm = SVC()\n",
    "#juste pour vérifier la validité de mon dictionnaire param_grid\n",
    "svm.get_params().keys()\n",
    "\n",
    "svm_grid = GridSearchCV(svm, param_grid, cv=5) \n",
    "svm_grid.fit(xtrain, ytrain) \n",
    "\n",
    "#pour obtenir les optimums\n",
    "print (\"les meilleurs paramètres selon GridSearchCV est :\", svm_grid.best_params_)\n",
    "print (\"la meilleure accuracy selon GridSearchCV est %.4f\"% svm_grid.best_score_)\n",
    "svm_grid_bestparam = svm_grid.best_params_\n",
    "svm_grid_bestscore = svm_grid.best_score_\n",
    "\n",
    "mon_svm_C = svm_grid.best_params_.get('C')\n",
    "mon_svm_gamma = svm_grid.best_params_.get('gamma')\n",
    "mon_svm_kernel = svm_grid.best_params_.get('kernel')\n",
    "print (\"ma SVM optimale a un C de\", mon_svm_C, \", un gamma de \",mon_svm_gamma, \" et un kernel de type \", mon_svm_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d'après gridsearchCV, il faut que j'utilise un C de 10 , un gamma de 0.001  et un kernel de type rbf\n",
      "j'obtiens une accuracy de 0.9798\n"
     ]
    }
   ],
   "source": [
    "#Scénatio alternatif 1 : classifieur SVM sur toutes les données, prédiction\n",
    "#On fait donc la prédiction avec les optimums de la SVM\n",
    "#print(\"On fait donc la prédiction avec\", GridCV_best_voisins,\" voisins\")\n",
    "print(\"d'après gridsearchCV, il faut que j'utilise un C de\", mon_svm_C, \", un gamma de\",mon_svm_gamma, \" et un kernel de type\", mon_svm_kernel)\n",
    "\n",
    "# une SVM avec les paramètres donnés par GridSearchCV\n",
    "svm_pred = SVC(C=mon_svm_C, kernel=mon_svm_kernel, gamma=mon_svm_gamma)\n",
    "# On créé le modèle avec les données d'entrainement\n",
    "svm_pred.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "# Et on prédit\n",
    "y_pred_svm = svm_pred.predict(xtest)\n",
    "\n",
    "svm_pred_accuracy = accuracy_score(ytest, y_pred_svm)\n",
    "print(\"j'obtiens une accuracy de %.4f\"% svm_pred_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les meilleurs paramètres selon GridSearchCV est : {'C': 0.1, 'penalty': 'l2'}\n",
      "la meilleure accuracy selon GridSearchCV est 0.9481\n",
      "ma SVM linaire optimale a un C de 10 , et une pénalité de  None\n"
     ]
    }
   ],
   "source": [
    "#Scénatio alternatif 2 : classifieur SVM linéaire sur toutes les données.\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "  \n",
    "# defining parameter range \n",
    "param_grid2 = {'penalty': ['l2'],  \n",
    "              'C': [0.1, 1, 10, 100, 1000]\n",
    "              }   \n",
    "\n",
    "\n",
    "svmlin = LinearSVC()\n",
    "#juste pour vérifier la validité de mon dictionnaire param_grid\n",
    "svmlin.get_params().keys()\n",
    "\n",
    "svmlin_grid = GridSearchCV(svmlin, param_grid2, cv=5) \n",
    "svmlin_grid.fit(xtrain, ytrain) \n",
    "\n",
    "#pour obtenir les optimums\n",
    "print (\"les meilleurs paramètres selon GridSearchCV est :\", svmlin_grid.best_params_)\n",
    "print (\"la meilleure accuracy selon GridSearchCV est %.4f\"% svmlin_grid.best_score_)\n",
    "svmlin_grid_bestparam = svmlin_grid.best_params_\n",
    "svmlin_grid_bestscore = svmlin_grid.best_score_\n",
    "\n",
    "mon_svmlin_C = svm_grid.best_params_.get('C')\n",
    "mon_svmlin_penalty = svm_grid.best_params_.get('penalty')\n",
    "print (\"ma SVM linaire optimale a un C de\", mon_svmlin_C, \", et une pénalité de \",mon_svmlin_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d'après gridsearchCV, il faut que j'utilise un C de 10 , et une pénalité de  None\n",
      "j'obtiens une accuracy de 0.9461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#Scénatio alternatif 2 : classifieur SVM linéaire sur toutes les données.\n",
    "#On fait donc la prédiction avec les optimums de la SVM linéaire\n",
    "print(\"d'après gridsearchCV, il faut que j'utilise un C de\", mon_svmlin_C, \", et une pénalité de \",mon_svmlin_penalty)\n",
    "\n",
    "# une SVM linéaire avec les paramètres donnés par GridSearchCV\n",
    "svmlin_pred = LinearSVC(C=mon_svmlin_C, penalty= 'l2')\n",
    "# On créé le modèle avec les données d'entrainement\n",
    "svmlin_pred.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "# Et on prédit\n",
    "y_pred_svmlin = svmlin_pred.predict(xtest)\n",
    "\n",
    "svmlin_pred_accuracy = accuracy_score(ytest, y_pred_svmlin)\n",
    "print(\"j'obtiens une accuracy de %.4f\"% svmlin_pred_accuracy)\n",
    "\n",
    "#roc_auc_score(ytest, y_pred_svmlin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il est temps de voir ce que le KNN  et la SVM ont donné : résumons les résultats.\n",
      " \n",
      "    Avec le KNN, j'obtiens une accuracy de 0.9529 avec 3 voisins.\n",
      "    Avec la SVM, j'obtiens une accuracy de 0.9798\n",
      "    Avec la SVM linéaire, j'obtiens une accuracy de 0.9461\n",
      " \n",
      "La SVM est le meilleur modèle pour ce problème.\n"
     ]
    }
   ],
   "source": [
    "#Il est temps de voir ce que le KNN  et la SVM ont donné : résumons les résultats.\n",
    "print (\"Il est temps de voir ce que le KNN  et la SVM ont donné : résumons les résultats.\")\n",
    "print(\" \")\n",
    "print(\"    Avec le KNN, j'obtiens une accuracy de %.4f\"% knn_pred_accuracy, \"avec\", mon_index_maison, \"voisins.\")\n",
    "print(\"    Avec la SVM, j'obtiens une accuracy de %.4f\"% svm_pred_accuracy)\n",
    "print(\"    Avec la SVM linéaire, j'obtiens une accuracy de %.4f\"% svmlin_pred_accuracy)\n",
    "print(\" \")\n",
    "print(\"La SVM est le meilleur modèle pour ce problème.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
